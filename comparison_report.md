# GPT-5.2-Codex 推理级别对比测试报告

**测试日期**: 2026年1月28日  
**模型**: gpt-5.2-codex  
**API端点**: Azure OpenAI (codex-cli-azure-resource)  
**测试模式**: Streaming  
**缓存设置**: 禁用 (--no-cache)  
**测试提示词**: "生成一个日历应用的代码示例，使用 Python 和 Tkinter 库。"

---

## 📊 测试结果汇总

| 指标 | High | Medium | Low |
| ------ | ------ | -------- | ----- |
| **总延迟 (ms)** | 64,823.74 | 31,374.98 | 22,858.35 |
| **首Token延迟 TTFT (ms)** | 46,581.64 | 6,680.84 | 4,053.07 |
| **输出 Tokens** | 1,838 | 695 | 481 |
| **TPS (tokens/s)** | 100.76 | 28.14 | 25.58 |
| **请求状态** | ✅ 成功 | ✅ 成功 | ✅ 成功 |

---

## 📈 性能对比分析

### 1. 总延迟 (Latency)

```text
High:   ████████████████████████████████████████████████████████████████ 64.82s (最慢)
Medium: █████████████████████████████████                               31.37s
Low:    ████████████████████████                                        22.86s (最快)
```

**分析**:

- **Low** 模式延迟最短（22.86秒），比 High 快 **64.7%**
- **Medium** 模式延迟 31.37 秒，比 High 快 **51.6%**
- 推理强度与延迟呈正相关

### 2. 首Token延迟 (TTFT - Time To First Token)

```text
Low:    ████████                   4,053.07ms (最快)
Medium: █████████████              6,680.84ms
High:   ██████████████████████████████████████████████ 46,581.64ms (最慢)
```

**分析**:

- **Low** 模式 TTFT 最快（4.05秒）
- **High** 模式 TTFT 显著偏高（46.58秒），首 token 延迟约为 Low 的 **11.5倍**
- High 模式的大部分时间花在"思考"阶段

### 3. 输出 Token 数量

```text
High:   ██████████████████████████████████████████████████████████████ 1,838 tokens (最多)
Medium: █████████████████████████                                      695 tokens
Low:    ████████████████████                                           481 tokens (最少)
```

**分析**:

- **High** 模式输出最丰富（1,838 tokens），约为 **Low** 的 **3.8倍**
- **Medium** 模式输出 695 tokens，介于两者之间
- 推理强度显著影响输出详细程度和代码完整性

### 4. Token 生成速度 (TPS)

```text
High:   ██████████████████████████████████████████████████ 100.76 tokens/s (最快)
Medium: ██████████████                                     28.14 tokens/s
Low:    █████████████                                      25.58 tokens/s (最慢)
```

**分析**:

- **High** 模式 TPS 最高（100.76），显著高于 Medium/Low
- High 模式虽然 TTFT 长，但一旦开始生成，速度极快
- Low/Medium 模式 TPS 相近（25-28 tokens/s）

---

## 🔍 效率指标分析

| 效率指标 | High | Medium | Low |
| ---------- | ------ | -------- | ----- |
| 每Token平均延迟 (ms) | 35.27 | 45.14 | 47.52 |
| 有效生成时间 (ms) | 18,242.10 | 24,694.14 | 18,805.28 |
| 思考时间估算 (ms) | ~46,582 | ~6,681 | ~4,053 |
| 输出效率 (tokens/总延迟s) | 28.35 | 22.15 | 21.04 |

---

## 🎯 场景推荐

| 场景 | 推荐级别 | 原因 |
| ------ | ---------- | ------ |
| ⚡ 快速原型/简单任务 | **Low** | 延迟最短（22.86s），快速获得反馈 |
| 🎯 生产代码/复杂逻辑 | **High** | 输出最完整（1,838 tokens），代码质量最高 |
| ⚖️ 平衡速度与质量 | **Medium** | 延迟适中（31.37s），输出丰富（695 tokens） |
| 🚀 高吞吐场景 | **High** | TPS 最高（100.76），生成阶段效率最佳 |

---

## 💡 关键发现

### ✅ 速度 vs 质量权衡

- Low 模式延迟最短，但输出量仅为 High 的 **26%**
- High 模式虽然总延迟长，但输出内容最完整

### ✅ TTFT 特征

- High 模式 TTFT 占总延迟的 **71.9%**（46.58s / 64.82s）
- Low/Medium 模式 TTFT 占比相对较低（17.7% / 21.3%）
- High 模式"思考"时间更长，但生成质量更高

### ✅ TPS 表现

- High 模式生成阶段 TPS 高达 **100.76 tokens/s**
- 一旦开始输出，High 模式生成速度是 Low 的 **3.9倍**

### ✅ 成本效益

- High 模式每秒输出更多有效 token（28.35 vs 21.04）
- 对于需要完整代码的场景，High 模式反而更具成本效益

---

## 📋 总结

| 排名 | 最快响应 | 最多输出 | 最高TPS | 最快TTFT |
| ------ | --------- | --------- | --------- | ---------- |
| 🥇 | Low (22.86s) | High (1,838) | High (100.76) | Low (4,053ms) |
| 🥈 | Medium (31.37s) | Medium (695) | Medium (28.14) | Medium (6,681ms) |
| 🥉 | High (64.82s) | Low (481) | Low (25.58) | High (46,582ms) |

**最终建议**:

- 日常开发调试：使用 **Low** 获得快速反馈
- 生成生产级代码：使用 **High** 获得最完整的实现
- 需要平衡速度与质量：使用 **Medium**

---
*报告生成时间: 2026年1月28日*  
*测试工具: LLMtest*
