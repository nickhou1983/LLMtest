# GPT-5.2-Codex 推理级别对比测试报告

**测试日期**: 2026年2月4日  
**模型**: gpt-5.2-codex  
**API端点**: Azure OpenAI (codex-cli-azure-resource)  
**测试模式**: Streaming  
**缓存设置**: 禁用 (--no-cache)  
**每级别测试次数**: 3次（取平均值）  
**测试提示词**: "生成一个日历应用的代码示例，使用 Python 和 Tkinter 库。"

---

## 📊 测试结果汇总

| 指标 | High | Medium | Low |
| ------ | ------ | -------- | ----- |
| **总延迟 (ms)** | 55,389.61 | 20,628.49 | 22,291.84 |
| **首Token延迟 TTFT (ms)** | 38,466.32 | 7,610.70 | 4,808.32 |
| **首推理响应 TTFR (ms)** | 12,356.24 | 6,631.27 | 4,538.93 |
| **输出 Tokens** | 1,451 | 609 | 471 |
| **TPS (tokens/s)** | 91.46 | 49.04 | 32.46 |
| **请求状态** | ✅ 成功 | ✅ 成功 | ✅ 成功 |

---

## 📈 性能对比分析

### 1. 总延迟 (Latency)

```text
High:   ████████████████████████████████████████████████████████████████ 55.39s (最慢)
Medium: ████████████████████████                                        20.63s (最快)
Low:    ██████████████████████████                                      22.29s
```

**分析**:

- **Medium** 模式延迟最短（20.63秒），比 High 快 **62.7%**
- **Low** 模式延迟 22.29 秒，比 High 快 **59.7%**
- 本次测试中 Medium 略优于 Low，可能与服务器负载有关

### 2. 首Token延迟 (TTFT - Time To First Token)

```text
Low:    ██████████                                                      4,808.32ms (最快)
Medium: ████████████████                                                7,610.70ms
High:   ██████████████████████████████████████████████████████████████ 38,466.32ms (最慢)
```

**分析**:

- **Low** 模式 TTFT 最快（4.81秒）
- **Medium** 模式 TTFT 为 7.61 秒
- **High** 模式 TTFT 显著偏高（38.47秒），首 token 延迟约为 Low 的 **8.0倍**
- High 模式的大部分时间花在"思考"阶段

### 3. 输出 Token 数量

```text
High:   ██████████████████████████████████████████████████████████████ 1,451 tokens (最多)
Medium: █████████████████████████                                        609 tokens
Low:    ████████████████████                                             471 tokens (最少)
```

**分析**:

- **High** 模式输出最丰富（1,451 tokens），约为 **Low** 的 **3.1倍**
- **Medium** 模式输出 609 tokens，介于两者之间
- 推理强度显著影响输出详细程度和代码完整性

### 4. Token 生成速度 (TPS)

```text
High:   ██████████████████████████████████████████████████████████████ 91.46 tokens/s (最快)
Medium: █████████████████████████████████                               49.04 tokens/s
Low:    ██████████████████████                                          32.46 tokens/s (最慢)
```

**分析**:

- **High** 模式 TPS 最高（91.46），显著高于 Medium/Low
- High 模式虽然 TTFT 长，但一旦开始生成，速度极快
- Medium 模式 TPS 49.04，Low 模式 TPS 32.46

---

## 🔍 效率指标分析

| 效率指标 | High | Medium | Low |
| ---------- | ------ | -------- | ----- |
| 每Token平均延迟 (ms) | 38.17 | 33.86 | 47.32 |
| 有效生成时间 (ms) | 16,923.29 | 13,017.79 | 17,483.52 |
| 首推理响应 TTFR (ms) | 12,356.24 | 6,631.27 | 4,538.93 |
| 思考时间估算 TTFT (ms) | 38,466.32 | 7,610.70 | 4,808.32 |
| 输出效率 (tokens/总延迟s) | 26.20 | 29.52 | 21.13 |

---

## 🎯 场景推荐

| 场景 | 推荐级别 | 原因 |
| ------ | ---------- | ------ |
| ⚡ 快速原型/简单任务 | **Low** | TTFT 最快（4.81s），快速获得首响应 |
| 🎯 生产代码/复杂逻辑 | **High** | 输出最完整（1,451 tokens），代码质量最高 |
| ⚖️ 平衡速度与质量 | **Medium** | 延迟最优（20.63s），输出较丰富（609 tokens） |
| 🚀 高吞吐场景 | **High** | TPS 最高（91.46），生成阶段效率最佳 |

---

## 💡 关键发现

### ✅ 速度 vs 质量权衡

- Medium 模式延迟最短，输出量约为 High 的 **42.0%**
- High 模式虽然总延迟长，但输出内容最完整

### ✅ TTFT 特征

- High 模式 TTFT 占总延迟的 **69.4%**（38.47s / 55.39s）
- Low 模式 TTFT 占比较低（21.6%）
- Medium 模式 TTFT 占比适中（36.9%）
- High 模式"思考"时间更长，但生成质量更高

### ✅ TPS 表现

- High 模式生成阶段 TPS 高达 **91.46 tokens/s**
- 一旦开始输出，High 模式生成速度是 Low 的 **2.8倍**

### ✅ TTFR 新指标

- 首推理响应时间（TTFR）更精确反映模型推理耗时
- High 模式 TTFR 约 12.4s，Medium 约 6.6s，Low 约 4.5s

### ✅ 成本效益

- Medium 模式每秒输出效率最高（29.52 tokens/总延迟s）
- 对于需要完整代码的场景，High 模式提供更多有价值的内容

---

## 📋 总结

| 排名 | 最快响应 | 最多输出 | 最高TPS | 最快TTFT |
| ------ | --------- | --------- | --------- | ---------- |
| 🥇 | Medium (20.63s) | High (1,451) | High (91.46) | Low (4,808ms) |
| 🥈 | Low (22.29s) | Medium (609) | Medium (49.04) | Medium (7,611ms) |
| 🥉 | High (55.39s) | Low (471) | Low (32.46) | High (38,466ms) |

**最终建议**:

- 日常开发调试：使用 **Medium** 获得最佳速度与质量平衡
- 生成生产级代码：使用 **High** 获得最完整的实现
- 需要最快首响应：使用 **Low**

---

## ⚠️ 备注

- 测试在相同网络环境下进行，结果可能因网络波动有所不同
- 推理强度设置影响模型的计算资源使用，可能影响成本
- 每级别运行3次取平均值，以减少随机波动
- 建议根据具体应用场景选择合适的推理级别

---

*报告生成时间: 2026年2月4日*  
*测试工具: LLMtest*  
*测试轮次: 每级别3次取平均值*
