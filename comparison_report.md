# GPT-5.2-Codex 推理级别对比测试报告

**测试日期**: 2026年1月31日  
**模型**: gpt-5.2-codex  
**API端点**: Azure OpenAI (codex-cli-azure-resource)  
**测试模式**: Streaming  
**缓存设置**: 禁用 (--no-cache)  
**每级别测试次数**: 3次（取平均值）  
**测试提示词**: "生成一个日历应用的代码示例，使用 Python 和 Tkinter 库。"

---

## 📊 测试结果汇总

| 指标 | High | Medium | Low |
| ------ | ------ | -------- | ----- |
| **总延迟 (ms)** | 35,818.86 | 15,902.15 | 14,982.29 |
| **首Token延迟 TTFT (ms)** | 23,505.26 | 5,145.63 | 4,690.03 |
| **首推理响应 TTFR (ms)** | 9,510.89 | 4,444.40 | 4,033.04 |
| **输出 Tokens** | 1,269 | 594 | 509 |
| **TPS (tokens/s)** | 109.87 | 55.74 | 49.74 |
| **请求状态** | ✅ 成功 | ✅ 成功 | ✅ 成功 |

---

## 📈 性能对比分析

### 1. 总延迟 (Latency)

```text
High:   ████████████████████████████████████████████████████████████████ 35.82s (最慢)
Medium: █████████████████████████████                                   15.90s
Low:    ███████████████████████████                                     14.98s (最快)
```

**分析**:

- **Low** 模式延迟最短（14.98秒），比 High 快 **58.2%**
- **Medium** 模式延迟 15.90 秒，比 High 快 **55.6%**
- 推理强度与延迟呈正相关

### 2. 首Token延迟 (TTFT - Time To First Token)

```text
Low:    █████████████                                                   4,690.03ms (最快)
Medium: ██████████████                                                  5,145.63ms
High:   ██████████████████████████████████████████████████████████████ 23,505.26ms (最慢)
```

**分析**:

- **Low** 模式 TTFT 最快（4.69秒）
- **High** 模式 TTFT 显著偏高（23.51秒），首 token 延迟约为 Low 的 **5.0倍**
- High 模式的大部分时间花在"思考"阶段

### 3. 输出 Token 数量

```text
High:   ██████████████████████████████████████████████████████████████ 1,269 tokens (最多)
Medium: █████████████████████████████                                    594 tokens
Low:    █████████████████████████                                        509 tokens (最少)
```

**分析**:

- **High** 模式输出最丰富（1,269 tokens），约为 **Low** 的 **2.5倍**
- **Medium** 模式输出 594 tokens，介于两者之间
- 推理强度显著影响输出详细程度和代码完整性

### 4. Token 生成速度 (TPS)

```text
High:   ██████████████████████████████████████████████████████████████ 109.87 tokens/s (最快)
Medium: ████████████████████████████████                                55.74 tokens/s
Low:    █████████████████████████████                                   49.74 tokens/s (最慢)
```

**分析**:

- **High** 模式 TPS 最高（109.87），显著高于 Medium/Low
- High 模式虽然 TTFT 长，但一旦开始生成，速度极快
- Medium 模式 TPS 55.74，Low 模式 TPS 49.74

---

## 🔍 效率指标分析

| 效率指标 | High | Medium | Low |
| ---------- | ------ | -------- | ----- |
| 每Token平均延迟 (ms) | 28.23 | 26.77 | 29.43 |
| 有效生成时间 (ms) | 12,313.60 | 10,756.52 | 10,292.26 |
| 首推理响应 TTFR (ms) | 9,510.89 | 4,444.40 | 4,033.04 |
| 思考时间估算 TTFT (ms) | 23,505.26 | 5,145.63 | 4,690.03 |
| 输出效率 (tokens/总延迟s) | 35.43 | 37.36 | 33.97 |

---

## 🎯 场景推荐

| 场景 | 推荐级别 | 原因 |
| ------ | ---------- | ------ |
| ⚡ 快速原型/简单任务 | **Low** | 延迟最短（14.98s），快速获得反馈 |
| 🎯 生产代码/复杂逻辑 | **High** | 输出最完整（1,269 tokens），代码质量最高 |
| ⚖️ 平衡速度与质量 | **Medium** | 延迟适中（15.90s），输出较丰富（594 tokens） |
| 🚀 高吞吐场景 | **High** | TPS 最高（109.87），生成阶段效率最佳 |

---

## 💡 关键发现

### ✅ 速度 vs 质量权衡

- Low 模式延迟最短，但输出量仅为 High 的 **40.1%**
- High 模式虽然总延迟长，但输出内容最完整

### ✅ TTFT 特征

- High 模式 TTFT 占总延迟的 **65.6%**（23.51s / 35.82s）
- Low/Medium 模式 TTFT 占比相对较低（31.3% / 32.4%）
- High 模式"思考"时间更长，但生成质量更高

### ✅ TPS 表现

- High 模式生成阶段 TPS 高达 **109.87 tokens/s**
- 一旦开始输出，High 模式生成速度是 Low 的 **2.2倍**

### ✅ TTFR 新指标

- 新增首推理响应时间（TTFR）指标，更精确反映模型推理耗时
- High 模式 TTFR 约 9.5s，Medium/Low 约 4-4.4s

### ✅ 成本效益

- Medium 模式每秒输出效率最高（37.36 tokens/总延迟s）
- 对于需要完整代码的场景，High 模式提供更多有价值的内容

---

## 📋 总结

| 排名 | 最快响应 | 最多输出 | 最高TPS | 最快TTFT |
| ------ | --------- | --------- | --------- | ---------- |
| 🥇 | Low (14.98s) | High (1,269) | High (109.87) | Low (4,690ms) |
| 🥈 | Medium (15.90s) | Medium (594) | Medium (55.74) | Medium (5,146ms) |
| 🥉 | High (35.82s) | Low (509) | Low (49.74) | High (23,505ms) |

**最终建议**:

- 日常开发调试：使用 **Low** 获得快速反馈
- 生成生产级代码：使用 **High** 获得最完整的实现
- 需要平衡速度与质量：使用 **Medium**

---

## ⚠️ 备注

- 测试在相同网络环境下进行，结果可能因网络波动有所不同
- 推理强度设置影响模型的计算资源使用，可能影响成本
- 每级别运行3次取平均值，以减少随机波动
- 建议根据具体应用场景选择合适的推理级别

---

*报告生成时间: 2026年1月31日*  
*测试工具: LLMtest*  
*测试轮次: 每级别3次取平均值*
